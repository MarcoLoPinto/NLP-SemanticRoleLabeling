{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fe2040e",
   "metadata": {
    "papermill": {
     "duration": 0.078963,
     "end_time": "2022-03-31T22:14:09.386664",
     "exception": false,
     "start_time": "2022-03-31T22:14:09.307701",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marco/miniconda3/envs/nlp2022-hw2/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5424a631",
   "metadata": {
    "papermill": {
     "duration": 0.049244,
     "end_time": "2022-03-31T22:14:12.552634",
     "exception": false,
     "start_time": "2022-03-31T22:14:12.503390",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Important paths for the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_root = '../../../../'\n",
    "test_name = 'test_temp'\n",
    "datasets_path = os.path.join(app_root, 'data')\n",
    "model_dir_path = os.path.join(app_root, 'model', test_name)\n",
    "\n",
    "datasets_paths = {}\n",
    "for lang in os.listdir(datasets_path):\n",
    "    dataset_lang_path = os.path.join(datasets_path, lang)\n",
    "    if os.path.isdir(dataset_lang_path):\n",
    "        datasets_paths[lang] = {}\n",
    "        for d_type in os.listdir(dataset_lang_path):\n",
    "            d_name = d_type.split('.')[0]\n",
    "            datasets_paths[lang][d_name] = os.path.join(dataset_lang_path, d_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path.append('../../../')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7bc95ee",
   "metadata": {
    "papermill": {
     "duration": 0.048851,
     "end_time": "2022-03-31T22:14:13.015246",
     "exception": false,
     "start_time": "2022-03-31T22:14:12.966395",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Setting the seed for reproducibility:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 28\n",
    "\n",
    "# random.seed(SEED) # not used\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_params = {\n",
    "    'batch_size': 32,\n",
    "    'PAD_TOKEN': '<pad>',\n",
    "    'UNK_TOKEN': '<unk>',\n",
    "    'transformer_name': \"bert-base-cased\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9214a0",
   "metadata": {
    "papermill": {
     "duration": 0.049393,
     "end_time": "2022-03-31T22:14:13.226777",
     "exception": false,
     "start_time": "2022-03-31T22:14:13.177384",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will use BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stud.modelsTests.dataset.SRLDataset_transformer_embtest import SRLDataset_transformer_embtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_en = SRLDataset_transformer_embtest(  datasets_paths['EN']['train'], \n",
    "                                                    tokenizer = global_params['transformer_name'],\n",
    "                                                    baselines_file_path = os.path.join(app_root,'data/baselines.json'))\n",
    "dataset_train_es = SRLDataset_transformer_embtest(  datasets_paths['ES']['train'], \n",
    "                                                    tokenizer = dataset_train_en.tokenizer,\n",
    "                                                    labels = dataset_train_en.labels)\n",
    "dataset_train_fr = SRLDataset_transformer_embtest(  datasets_paths['FR']['train'], \n",
    "                                                    tokenizer = dataset_train_en.tokenizer,\n",
    "                                                    labels = dataset_train_en.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRLDataset_transformer_embtest.save_dict(\n",
    "    os.path.join(model_dir_path, 'labels.npy'), \n",
    "    dataset_train_en.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dev_en = SRLDataset_transformer_embtest(datasets_paths['EN']['dev'], \n",
    "                                                tokenizer = dataset_train_en.tokenizer,\n",
    "                                                labels = dataset_train_en.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['dependency_heads', 'dependency_relations', 'lemmas', 'pos_tags', 'predicates', 'roles', 'words', 'predicate_position', 'predicate_label', 'predicate_word'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(dataset_train_en)).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_params.update({ \n",
    "    'n_roles_labels': len(dataset_train_en.labels['id_to_roles']),\n",
    "    'n_predicates_labels': len(dataset_train_en.labels['id_to_predicates']),\n",
    "    'n_dependency_relations_labels': len(dataset_train_en.labels['id_to_dependency_relations']),\n",
    "    'n_pos_labels': len(dataset_train_en.labels['id_to_pos']),\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15baf7b6",
   "metadata": {},
   "source": [
    "Saving global variables..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(model_dir_path, 'global_params.npy'), global_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "num_workers = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_train_en = DataLoader(\n",
    "    dataset_train_en,\n",
    "    batch_size=global_params['batch_size'],\n",
    "    collate_fn=dataset_train_en.create_collate_fn(),\n",
    "    num_workers=num_workers,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_dev_en = DataLoader(\n",
    "    dataset_dev_en,\n",
    "    batch_size=global_params['batch_size'],\n",
    "    collate_fn=dataset_dev_en.create_collate_fn(),\n",
    "    num_workers=num_workers,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in dataloader_dev_en:\n",
    "    ex_in = e\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'roles', 'matrix_subwords', 'output_mask', 'predicates', 'predicate_position_raw', 'predicate_position', 'pos_tags', 'formatted_word_ids'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_in.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  101,  1109,  2341, 18029,  1116,  1115,  1103,  1426,  1710,  2653,\n",
      "         1167,  2209,  1106, 14516,  2316, 17030,  6185,  1103,  1484,  1104,\n",
      "         1103,  1644,  7742,  6421,   117,  2699,  1105,  4223,  2088,  1164,\n",
      "         1769,  2266,   119,   102, 18029,  1116,   102,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0]) torch.Size([32, 80])\n",
      "tensor([0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]) torch.Size([32, 80])\n",
      "tensor([-1,  0,  1,  0, -1, 11,  0,  0,  0,  0,  0,  0,  0,  0, -1, -1, -1,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1]) torch.Size([32, 80])\n",
      "tensor([-1,  0,  1,  2,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 11, 11, 11, 12,\n",
      "        13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1]) torch.Size([32, 80])\n"
     ]
    }
   ],
   "source": [
    "print(ex_in['input_ids'][0], ex_in['input_ids'].shape)\n",
    "print(ex_in['output_mask'][0], ex_in['output_mask'].shape)\n",
    "print(ex_in['roles'][0], ex_in['roles'].shape)\n",
    "print(ex_in['formatted_word_ids'][0], ex_in['formatted_word_ids'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -1,   0,   0, 162,  -1,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         -1,  -1,  -1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
      "         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
      "         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
      "         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1]) torch.Size([32, 80])\n",
      "tensor(3) torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "print(ex_in['predicates'][0], ex_in['predicates'].shape)\n",
    "print(ex_in['predicate_position'][0], ex_in['predicate_position'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 80, 80]) \n",
      " tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 1, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "torch.set_printoptions(edgeitems=80)\n",
    "print(ex_in['matrix_subwords'].shape,'\\n' , ex_in['matrix_subwords'][0][0:6,:10]) # word_ids[0:6] = [None, 0, 1, 2, 2, 3]\n",
    "torch.set_printoptions(edgeitems=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Printing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "def print_summary(model):\n",
    "    print(model)\n",
    "    print('----------------------')\n",
    "    p = sum(p.numel() for p in model.parameters())\n",
    "    tp = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    ntp = p - tp\n",
    "    print('parameters:', f'{p:,}')\n",
    "    print('trainable parameters:', f'{tp:,}')\n",
    "    print('non-trainable parameters:', f'{ntp:,}')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def display_history(dict_history):\n",
    "    plt.figure(figsize=(8,8))\n",
    "    for name, hist in dict_history.items():\n",
    "        plt.plot([i for i in range(len(hist))], hist, label=name)\n",
    "    plt.xlabel('epochs')\n",
    "    plt.ylabel('value')\n",
    "    plt.title('Model learning')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = torch.nn.CrossEntropyLoss(ignore_index = dataset_train_en.labels['roles_pad_id']) # !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model with matrix computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from stud.modelsTests.model_arg_iden_class_part.Model_aic_transformer_embtest import ArgIdenClassModel\n",
    "import torch.optim as optim\n",
    "\n",
    "final_model = ArgIdenClassModel(\n",
    "    language = 'EN',\n",
    "    device = device,\n",
    "    model_load_weights = False,\n",
    "    loss_fn = loss_function,\n",
    "    fine_tune_transformer = True,\n",
    "    saves_path_folder = test_name,\n",
    ")\n",
    "\n",
    "optimizer = optim.SGD(final_model.model.parameters(), lr=0.0016, momentum=0.9)\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.0016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net_aic_transformer_embtest(\n",
      "  (transformer_model): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (6): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (7): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (8): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (9): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (10): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (11): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (classifier): Linear(in_features=768, out_features=13, bias=True)\n",
      "  (loss_fn): CrossEntropyLoss()\n",
      ")\n",
      "----------------------\n",
      "parameters: 108,320,269\n",
      "trainable parameters: 108,320,269\n",
      "non-trainable parameters: 0\n"
     ]
    }
   ],
   "source": [
    "print_summary(final_model.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This first test uses a crafted matrix in order to compute the mean of subwords vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    def forward(\n",
      "        self, \n",
      "        input_ids, \n",
      "        attention_mask, \n",
      "        matrix_subwords,\n",
      "        token_type_ids = None,\n",
      "    ):\n",
      "        \n",
      "        # Embedding (transformer)\n",
      "\n",
      "        transformer_kwargs = {\n",
      "            'input_ids': input_ids,\n",
      "            'attention_mask': attention_mask,\n",
      "        }\n",
      "\n",
      "        if token_type_ids is None: # some transformer models don't have it\n",
      "            transformer_kwargs['token_type_ids'] = token_type_ids\n",
      "\n",
      "        n_transformer_hidden_states = 4\n",
      "\n",
      "        transformer_outs = self.transformer_model(**transformer_kwargs)\n",
      "\n",
      "        transformer_out = torch.stack(\n",
      "            transformer_outs.hidden_states[-n_transformer_hidden_states:],\n",
      "            dim=0).sum(dim=0)\n",
      "\n",
      "        # Matrix computation\n",
      "\n",
      "        matrix_ex_reshaped = torch.swapaxes(matrix_subwords,0,1)\n",
      "\n",
      "        res_prod = (matrix_ex_reshaped[:,:,:,None] * transformer_out[None,:,:,:])\n",
      "        res_prod = torch.swapaxes(res_prod,0,1)\n",
      "\n",
      "        matrix_ex_mask = matrix_subwords.count_nonzero(-1)\n",
      "        matrix_ex_mask = torch.where(matrix_ex_mask>0,matrix_ex_mask,1)\n",
      "\n",
      "        matrix_out = (res_prod.sum(dim=-2) / matrix_ex_mask[:,:,None])\n",
      "\n",
      "        # Classifier\n",
      "        \n",
      "        logits = self.classifier(matrix_out)\n",
      "\n",
      "        return logits # (batch, sentence_len, n_lables)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from inspect import getsource\n",
    "print(getsource(final_model.model.forward))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 => avg_loss: 0.202119\n",
      "# Validation loss => 0.096276 | f1-score: arg_iden = 0.755846 arg_class = 0.562815 #\n",
      "Epoch   1 => avg_loss: 0.090979\n",
      "# Validation loss => 0.071629 | f1-score: arg_iden = 0.842551 arg_class = 0.664971 #\n",
      "Epoch   2 => avg_loss: 0.073753\n",
      "# Validation loss => 0.063421 | f1-score: arg_iden = 0.866421 arg_class = 0.703954 #\n",
      "Epoch   3 => avg_loss: 0.063903\n",
      "# Validation loss => 0.058030 | f1-score: arg_iden = 0.873329 arg_class = 0.732673 #\n",
      "Epoch   4 => avg_loss: 0.057295\n",
      "# Validation loss => 0.055054 | f1-score: arg_iden = 0.878669 arg_class = 0.749370 #\n",
      "Epoch   5 => avg_loss: 0.052990\n",
      "# Validation loss => 0.051891 | f1-score: arg_iden = 0.879502 arg_class = 0.764616 #\n",
      "Epoch   6 => avg_loss: 0.049018\n",
      "# Validation loss => 0.051601 | f1-score: arg_iden = 0.882753 arg_class = 0.766106 #\n",
      "Epoch   7 => avg_loss: 0.046112\n",
      "# Validation loss => 0.049732 | f1-score: arg_iden = 0.881959 arg_class = 0.781999 #\n",
      "Epoch   8 => avg_loss: 0.044086\n",
      "# Validation loss => 0.048034 | f1-score: arg_iden = 0.882663 arg_class = 0.784409 #\n",
      "Epoch   9 => avg_loss: 0.041684\n",
      "# Validation loss => 0.048271 | f1-score: arg_iden = 0.884372 arg_class = 0.785348 #\n",
      "Epoch  10 => avg_loss: 0.040240\n",
      "# Validation loss => 0.047525 | f1-score: arg_iden = 0.879388 arg_class = 0.789257 #\n",
      "Epoch  11 => avg_loss: 0.038474\n",
      "# Validation loss => 0.046671 | f1-score: arg_iden = 0.886556 arg_class = 0.791683 #\n",
      "Epoch  12 => avg_loss: 0.037110\n",
      "# Validation loss => 0.047387 | f1-score: arg_iden = 0.885331 arg_class = 0.792876 #\n",
      "Epoch  13 => avg_loss: 0.035383\n",
      "# Validation loss => 0.046181 | f1-score: arg_iden = 0.884200 arg_class = 0.796971 #\n",
      "Epoch  14 => avg_loss: 0.034591\n",
      "# Validation loss => 0.046021 | f1-score: arg_iden = 0.882317 arg_class = 0.797853 #\n",
      "Epoch  15 => avg_loss: 0.033577\n",
      "# Validation loss => 0.046840 | f1-score: arg_iden = 0.884154 arg_class = 0.794518 #\n",
      "Epoch  16 => avg_loss: 0.032316\n",
      "# Validation loss => 0.045713 | f1-score: arg_iden = 0.885326 arg_class = 0.801502 #\n",
      "----- Best value obtained, saving model -----\n",
      "Epoch  17 => avg_loss: 0.031408\n",
      "# Validation loss => 0.046468 | f1-score: arg_iden = 0.884189 arg_class = 0.799396 #\n",
      "Epoch  18 => avg_loss: 0.030483\n",
      "# Validation loss => 0.045878 | f1-score: arg_iden = 0.885838 arg_class = 0.803876 #\n",
      "----- Best value obtained, saving model -----\n",
      "Epoch  19 => avg_loss: 0.029494\n",
      "# Validation loss => 0.046319 | f1-score: arg_iden = 0.884864 arg_class = 0.802104 #\n",
      "Epoch  20 => avg_loss: 0.028526\n",
      "# Validation loss => 0.046159 | f1-score: arg_iden = 0.884780 arg_class = 0.804511 #\n",
      "----- Best value obtained, saving model -----\n",
      "Epoch  21 => avg_loss: 0.027961\n",
      "# Validation loss => 0.047202 | f1-score: arg_iden = 0.885105 arg_class = 0.802765 #\n",
      "Epoch  22 => avg_loss: 0.026893\n",
      "# Validation loss => 0.047998 | f1-score: arg_iden = 0.884531 arg_class = 0.802481 #\n",
      "Epoch  23 => avg_loss: 0.026582\n",
      "# Validation loss => 0.049006 | f1-score: arg_iden = 0.884954 arg_class = 0.798101 #\n",
      "Epoch  24 => avg_loss: 0.025540\n",
      "# Validation loss => 0.049256 | f1-score: arg_iden = 0.885317 arg_class = 0.799724 #\n",
      "Epoch  25 => avg_loss: 0.025074\n",
      "# Validation loss => 0.047490 | f1-score: arg_iden = 0.887004 arg_class = 0.806018 #\n",
      "----- Best value obtained, saving model -----\n",
      "Epoch  26 => avg_loss: 0.024179\n",
      "# Validation loss => 0.047583 | f1-score: arg_iden = 0.886872 arg_class = 0.808429 #\n",
      "----- Best value obtained, saving model -----\n",
      "Epoch  27 => avg_loss: 0.023312\n",
      "# Validation loss => 0.048570 | f1-score: arg_iden = 0.884615 arg_class = 0.806290 #\n",
      "Epoch  28 => avg_loss: 0.022762\n",
      "# Validation loss => 0.049202 | f1-score: arg_iden = 0.885671 arg_class = 0.807240 #\n",
      "Epoch  29 => avg_loss: 0.022241\n",
      "# Validation loss => 0.048717 | f1-score: arg_iden = 0.884194 arg_class = 0.805514 #\n",
      "Epoch  30 => avg_loss: 0.021898\n",
      "# Validation loss => 0.049234 | f1-score: arg_iden = 0.885060 arg_class = 0.806375 #\n",
      "Epoch  31 => avg_loss: 0.021044\n",
      "# Validation loss => 0.048772 | f1-score: arg_iden = 0.884580 arg_class = 0.811288 #\n",
      "----- Best value obtained, saving model -----\n",
      "Epoch  32 => avg_loss: 0.020472\n",
      "# Validation loss => 0.050624 | f1-score: arg_iden = 0.886246 arg_class = 0.808277 #\n",
      "Epoch  33 => avg_loss: 0.019956\n",
      "# Validation loss => 0.050474 | f1-score: arg_iden = 0.883585 arg_class = 0.809548 #\n",
      "Epoch  34 => avg_loss: 0.019304\n",
      "# Validation loss => 0.050251 | f1-score: arg_iden = 0.883187 arg_class = 0.809739 #\n",
      "Epoch  35 => avg_loss: 0.018927\n",
      "# Validation loss => 0.050686 | f1-score: arg_iden = 0.884836 arg_class = 0.809471 #\n",
      "Epoch  36 => avg_loss: 0.018218\n",
      "# Validation loss => 0.051094 | f1-score: arg_iden = 0.884696 arg_class = 0.808630 #\n",
      "Epoch  37 => avg_loss: 0.018026\n",
      "# Validation loss => 0.051446 | f1-score: arg_iden = 0.884837 arg_class = 0.810088 #\n",
      "Epoch  38 => avg_loss: 0.017282\n",
      "# Validation loss => 0.051788 | f1-score: arg_iden = 0.883834 arg_class = 0.809625 #\n",
      "Epoch  39 => avg_loss: 0.016684\n",
      "# Validation loss => 0.052137 | f1-score: arg_iden = 0.883253 arg_class = 0.807770 #\n",
      "Epoch  40 => avg_loss: 0.016414\n",
      "# Validation loss => 0.053248 | f1-score: arg_iden = 0.884550 arg_class = 0.811475 #\n",
      "----- Best value obtained, saving model -----\n",
      "Epoch  41 => avg_loss: 0.015903\n",
      "# Validation loss => 0.053269 | f1-score: arg_iden = 0.884134 arg_class = 0.810254 #\n",
      "Epoch  42 => avg_loss: 0.015726\n",
      "# Validation loss => 0.054107 | f1-score: arg_iden = 0.885654 arg_class = 0.807750 #\n",
      "Epoch  43 => avg_loss: 0.015344\n",
      "# Validation loss => 0.054287 | f1-score: arg_iden = 0.883005 arg_class = 0.807673 #\n",
      "Epoch  44 => avg_loss: 0.014807\n",
      "# Validation loss => 0.055132 | f1-score: arg_iden = 0.884337 arg_class = 0.808835 #\n",
      "Epoch  45 => avg_loss: 0.014358\n",
      "# Validation loss => 0.055405 | f1-score: arg_iden = 0.882859 arg_class = 0.809571 #\n",
      "Epoch  46 => avg_loss: 0.014265\n",
      "# Validation loss => 0.055292 | f1-score: arg_iden = 0.884995 arg_class = 0.810838 #\n",
      "Epoch  47 => avg_loss: 0.013541\n",
      "# Validation loss => 0.056028 | f1-score: arg_iden = 0.885458 arg_class = 0.811989 #\n",
      "----- Best value obtained, saving model -----\n",
      "Epoch  48 => avg_loss: 0.013342\n",
      "# Validation loss => 0.056005 | f1-score: arg_iden = 0.886109 arg_class = 0.810451 #\n",
      "Epoch  49 => avg_loss: 0.013067\n",
      "# Validation loss => 0.056909 | f1-score: arg_iden = 0.885723 arg_class = 0.809740 #\n",
      "Epoch  50 => avg_loss: 0.012856\n",
      "# Validation loss => 0.056898 | f1-score: arg_iden = 0.883852 arg_class = 0.810632 #\n",
      "Epoch  51 => avg_loss: 0.012880\n",
      "# Validation loss => 0.057282 | f1-score: arg_iden = 0.883997 arg_class = 0.812425 #\n",
      "----- Best value obtained, saving model -----\n",
      "Epoch  52 => avg_loss: 0.011911\n",
      "# Validation loss => 0.057840 | f1-score: arg_iden = 0.882484 arg_class = 0.810073 #\n",
      "Epoch  53 => avg_loss: 0.011795\n",
      "# Validation loss => 0.059776 | f1-score: arg_iden = 0.883171 arg_class = 0.808489 #\n",
      "Epoch  54 => avg_loss: 0.011789\n",
      "# Validation loss => 0.059162 | f1-score: arg_iden = 0.884288 arg_class = 0.811081 #\n",
      "Epoch  55 => avg_loss: 0.011452\n",
      "# Validation loss => 0.058155 | f1-score: arg_iden = 0.883918 arg_class = 0.811165 #\n",
      "Epoch  56 => avg_loss: 0.011380\n",
      "# Validation loss => 0.059793 | f1-score: arg_iden = 0.883218 arg_class = 0.807165 #\n",
      "Epoch  57 => avg_loss: 0.011137\n",
      "# Validation loss => 0.060143 | f1-score: arg_iden = 0.883190 arg_class = 0.807654 #\n",
      "Epoch  58 => avg_loss: 0.010720\n",
      "# Validation loss => 0.059737 | f1-score: arg_iden = 0.884001 arg_class = 0.808476 #\n",
      "Epoch  59 => avg_loss: 0.010506\n",
      "# Validation loss => 0.061672 | f1-score: arg_iden = 0.882166 arg_class = 0.804538 #\n"
     ]
    }
   ],
   "source": [
    "from stud.modelsTests.utils.Trainer_aic_transformer_embtest import Trainer_aic_transformer_embtest\n",
    "\n",
    "trainer = Trainer_aic_transformer_embtest()\n",
    "\n",
    "history = trainer.train(\n",
    "    final_model, optimizer, dataloader_train_en, dataloader_dev_en,\n",
    "    epochs=60, device=device,\n",
    "    save_best=True, \n",
    "    min_score=0.8,\n",
    "    save_path_name=os.path.join(model_dir_path, 'arg_iden_class_net_weights.pth'),\n",
    "    saved_history=history\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reformatting the matrix output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from stud.modelsTests.model_arg_iden_class_part.Model_aic_transformer_embtest import ArgIdenClassModel\n",
    "import torch.optim as optim\n",
    "\n",
    "final_model = ArgIdenClassModel(\n",
    "    language = 'EN',\n",
    "    device = device,\n",
    "    model_load_weights = False,\n",
    "    loss_fn = loss_function,\n",
    "    fine_tune_transformer = True,\n",
    "    saves_path_folder = test_name,\n",
    ")\n",
    "\n",
    "optimizer = optim.SGD(final_model.model.parameters(), lr=0.0016, momentum=0.9)\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.0016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net_aic_transformer_embtest(\n",
      "  (transformer_model): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (6): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (7): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (8): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (9): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (10): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (11): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (encoder): TransformerEncoder(\n",
      "    (layers): ModuleList(\n",
      "      (0): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=1020, out_features=1020, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=1020, out_features=2048, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=2048, out_features=1020, bias=True)\n",
      "        (norm1): LayerNorm((1020,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((1020,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (1): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=1020, out_features=1020, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=1020, out_features=2048, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=2048, out_features=1020, bias=True)\n",
      "        (norm1): LayerNorm((1020,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((1020,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (classifier): Linear(in_features=1020, out_features=13, bias=True)\n",
      "  (loss_fn): CrossEntropyLoss()\n",
      ")\n",
      "----------------------\n",
      "parameters: 125,025,041\n",
      "trainable parameters: 125,025,041\n",
      "non-trainable parameters: 0\n"
     ]
    }
   ],
   "source": [
    "print_summary(final_model.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This first test uses a crafted matrix in order to compute the mean of subwords vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    def forward(\n",
      "        self, \n",
      "        input_ids, \n",
      "        attention_mask, \n",
      "        matrix_subwords,\n",
      "        formatted_word_ids,\n",
      "        batch_sentence_predicates,\n",
      "        batch_predicate_position,\n",
      "        batch_pos_tags,\n",
      "\n",
      "        token_type_ids = None,\n",
      "    ):\n",
      "        \n",
      "        # ) Embedding (transformer)\n",
      "\n",
      "        transformer_kwargs = {\n",
      "            'input_ids': input_ids,\n",
      "            'attention_mask': attention_mask,\n",
      "        }\n",
      "\n",
      "        if token_type_ids is None: # some transformer models don't have it\n",
      "            transformer_kwargs['token_type_ids'] = token_type_ids\n",
      "\n",
      "        n_transformer_hidden_states = 4\n",
      "\n",
      "        transformer_outs = self.transformer_model(**transformer_kwargs)\n",
      "\n",
      "        transformer_out = torch.stack( # transformer_out = (batch, sentence_len, 768)\n",
      "            transformer_outs.hidden_states[-n_transformer_hidden_states:],\n",
      "            dim=0).sum(dim=0)\n",
      "\n",
      "        # # Matrix computation\n",
      "\n",
      "        # matrix_ex_reshaped = torch.swapaxes(matrix_subwords,0,1)\n",
      "\n",
      "        # res_prod = (matrix_ex_reshaped[:,:,:,None] * transformer_out[None,:,:,:])\n",
      "        # res_prod = torch.swapaxes(res_prod,0,1)\n",
      "\n",
      "        # matrix_ex_mask = matrix_subwords.count_nonzero(-1)\n",
      "        # matrix_ex_mask = torch.where(matrix_ex_mask>0,matrix_ex_mask,1)\n",
      "\n",
      "        # matrix_out = (res_prod.sum(dim=-2) / matrix_ex_mask[:,:,None])\n",
      "\n",
      "        # # Word id computation\n",
      "\n",
      "        # matrix_computed_formatted = torch.zeros(matrix_out.shape).to(self.get_device())\n",
      "        # for b, batch in enumerate(matrix_out):\n",
      "        #     previous_id = None\n",
      "        #     for i, word_vector in enumerate(batch):\n",
      "        #         pos = formatted_word_ids[b][i]\n",
      "        #         if pos != -1 and pos != previous_id:\n",
      "        #             matrix_computed_formatted[b][pos] = matrix_out[b][i]\n",
      "        #         previous_id = pos\n",
      "\n",
      "        # matrix_computed_formatted = self._compute_matrix(matrix_subwords, formatted_word_ids)\n",
      "\n",
      "        # # ) Seq encoder\n",
      "\n",
      "        # # For each sentence in the batch, it generates an array of the same length as the sentence:\n",
      "        # # the only 1 in each array corresponds to the position of the predicate in the sentence.\n",
      "        # # If the position of the target predicate is equal to -1, then the encoding for it becomes [0,0,...,0] \n",
      "        # # (i.e. there is no target predicate for that sentence).\n",
      "        # # predicate_mask has shape (batch, sentence_len)\n",
      "        # predicate_mask = torch.nn.functional.one_hot( \n",
      "        #     torch.where(batch_predicate_position >=0 , batch_predicate_position , 0) , \n",
      "        #     num_classes=input_ids.shape[-1] \n",
      "        # ) * (batch_predicate_position >= 0)[:,None]\n",
      "\n",
      "        # For each word in the sentence (or not, like '_') it associates a one-hot representation\n",
      "        # for that particular word.\n",
      "        # If a predicate is equal to -1, then the encoding for it becomes [0,0,...,0]\n",
      "        # (i.e. that particular word in the sentence is padding, so convert to a vector of zeros)\n",
      "        # batch_sentence_predicates_onehot has shape (batch, sentence_len, n_predicates)\n",
      "        batch_sentence_predicates_onehot = torch.nn.functional.one_hot( \n",
      "            torch.where(batch_sentence_predicates >=0 , batch_sentence_predicates , 0), \n",
      "            num_classes=self.n_predicates,\n",
      "        ) * (batch_sentence_predicates >= 0)[:,:,None]\n",
      "\n",
      "        # For each word in the sentence (or not, like '_') it associates a one-hot representation\n",
      "        # for that particular word (pos tag).\n",
      "        # If a pos is equal to -1, then the encoding for it becomes [0,0,...,0]\n",
      "        # (i.e. that particular word in the sentence is padding, so convert to a vector of zeros)\n",
      "        # batch_sentence_pos_onehot has shape (batch, sentence_len, n_pos_tags)\n",
      "        batch_sentence_pos_onehot = torch.nn.functional.one_hot( \n",
      "            torch.where(batch_pos_tags >=0 , batch_pos_tags , 0), \n",
      "            num_classes=self.n_pos_tags,\n",
      "        ) * (batch_pos_tags >= 0)[:,:,None]\n",
      "    \n",
      "        batch_sentence_words = torch.cat((\n",
      "            transformer_out, \n",
      "            batch_sentence_predicates_onehot, \n",
      "            batch_sentence_pos_onehot,\n",
      "        ), dim=-1)\n",
      "\n",
      "        # batch_sentence_words, _ = self.word_lstm(batch_sentence_words)\n",
      "\n",
      "        # ) Pre-classifier\n",
      "\n",
      "        batch_sentence_words_out = self.encoder(batch_sentence_words)\n",
      "\n",
      "        batch_sentence_words = torch.sum(torch.stack([batch_sentence_words, batch_sentence_words_out]), dim=0)\n",
      "\n",
      "        # ) Classifier\n",
      "        \n",
      "        logits = self.classifier(batch_sentence_words)\n",
      "\n",
      "        return logits # (batch, sentence_len, n_lables)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from inspect import getsource\n",
    "print(getsource(final_model.model.forward))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 => avg_loss: 0.324830\n",
      "# Validation loss => 0.173260 | f1-score: arg_iden = 0.246826 arg_class = 0.195107 #\n",
      "Epoch   1 => avg_loss: 0.149614\n",
      "# Validation loss => 0.099617 | f1-score: arg_iden = 0.778779 arg_class = 0.539982 #\n",
      "Epoch   2 => avg_loss: 0.102740\n",
      "# Validation loss => 0.084274 | f1-score: arg_iden = 0.844768 arg_class = 0.594307 #\n",
      "Epoch   3 => avg_loss: 0.087478\n",
      "# Validation loss => 0.073713 | f1-score: arg_iden = 0.850208 arg_class = 0.635154 #\n",
      "Epoch   4 => avg_loss: 0.079006\n",
      "# Validation loss => 0.068071 | f1-score: arg_iden = 0.873059 arg_class = 0.667219 #\n",
      "Epoch   5 => avg_loss: 0.072212\n",
      "# Validation loss => 0.065487 | f1-score: arg_iden = 0.875579 arg_class = 0.687940 #\n",
      "Epoch   6 => avg_loss: 0.066722\n",
      "# Validation loss => 0.060419 | f1-score: arg_iden = 0.876628 arg_class = 0.713363 #\n",
      "Epoch   7 => avg_loss: 0.061533\n",
      "# Validation loss => 0.056436 | f1-score: arg_iden = 0.878729 arg_class = 0.730907 #\n",
      "Epoch   8 => avg_loss: 0.057159\n",
      "# Validation loss => 0.054697 | f1-score: arg_iden = 0.884819 arg_class = 0.747660 #\n",
      "Epoch   9 => avg_loss: 0.053335\n",
      "# Validation loss => 0.052341 | f1-score: arg_iden = 0.884780 arg_class = 0.759195 #\n",
      "Epoch  10 => avg_loss: 0.050323\n",
      "# Validation loss => 0.050600 | f1-score: arg_iden = 0.879892 arg_class = 0.762698 #\n",
      "Epoch  11 => avg_loss: 0.047669\n",
      "# Validation loss => 0.050356 | f1-score: arg_iden = 0.887191 arg_class = 0.769556 #\n",
      "Epoch  12 => avg_loss: 0.045040\n",
      "# Validation loss => 0.049165 | f1-score: arg_iden = 0.887003 arg_class = 0.772267 #\n",
      "Epoch  13 => avg_loss: 0.043715\n",
      "# Validation loss => 0.049554 | f1-score: arg_iden = 0.887620 arg_class = 0.778846 #\n",
      "Epoch  14 => avg_loss: 0.041621\n",
      "# Validation loss => 0.047494 | f1-score: arg_iden = 0.887585 arg_class = 0.781544 #\n",
      "Epoch  15 => avg_loss: 0.040147\n",
      "# Validation loss => 0.048011 | f1-score: arg_iden = 0.886244 arg_class = 0.782574 #\n",
      "Epoch  16 => avg_loss: 0.038500\n",
      "# Validation loss => 0.047226 | f1-score: arg_iden = 0.888462 arg_class = 0.786328 #\n",
      "Epoch  17 => avg_loss: 0.037135\n",
      "# Validation loss => 0.046948 | f1-score: arg_iden = 0.889385 arg_class = 0.790429 #\n",
      "Epoch  18 => avg_loss: 0.036192\n",
      "# Validation loss => 0.046197 | f1-score: arg_iden = 0.886260 arg_class = 0.790618 #\n",
      "Epoch  19 => avg_loss: 0.034512\n",
      "# Validation loss => 0.046550 | f1-score: arg_iden = 0.887194 arg_class = 0.792798 #\n",
      "Epoch  20 => avg_loss: 0.033424\n",
      "# Validation loss => 0.045755 | f1-score: arg_iden = 0.890289 arg_class = 0.791954 #\n",
      "Epoch  21 => avg_loss: 0.032074\n",
      "# Validation loss => 0.047284 | f1-score: arg_iden = 0.890636 arg_class = 0.792662 #\n",
      "Epoch  22 => avg_loss: 0.031250\n",
      "# Validation loss => 0.046667 | f1-score: arg_iden = 0.889181 arg_class = 0.793413 #\n",
      "Epoch  23 => avg_loss: 0.030170\n",
      "# Validation loss => 0.047692 | f1-score: arg_iden = 0.888597 arg_class = 0.793773 #\n",
      "Epoch  24 => avg_loss: 0.029365\n",
      "# Validation loss => 0.048160 | f1-score: arg_iden = 0.891742 arg_class = 0.794501 #\n",
      "Epoch  25 => avg_loss: 0.028282\n",
      "# Validation loss => 0.047457 | f1-score: arg_iden = 0.889449 arg_class = 0.797340 #\n",
      "Epoch  26 => avg_loss: 0.027943\n",
      "# Validation loss => 0.047864 | f1-score: arg_iden = 0.888025 arg_class = 0.801842 #\n",
      "----- Best value obtained, saving model -----\n",
      "Epoch  27 => avg_loss: 0.026858\n",
      "# Validation loss => 0.048136 | f1-score: arg_iden = 0.888643 arg_class = 0.798191 #\n",
      "Epoch  28 => avg_loss: 0.026368\n",
      "# Validation loss => 0.048138 | f1-score: arg_iden = 0.889247 arg_class = 0.796701 #\n",
      "Epoch  29 => avg_loss: 0.025179\n",
      "# Validation loss => 0.048463 | f1-score: arg_iden = 0.889852 arg_class = 0.798750 #\n",
      "Epoch  30 => avg_loss: 0.024660\n",
      "# Validation loss => 0.049182 | f1-score: arg_iden = 0.888032 arg_class = 0.800203 #\n",
      "Epoch  31 => avg_loss: 0.024130\n",
      "# Validation loss => 0.048035 | f1-score: arg_iden = 0.888529 arg_class = 0.796480 #\n",
      "Epoch  32 => avg_loss: 0.023500\n",
      "# Validation loss => 0.049085 | f1-score: arg_iden = 0.887631 arg_class = 0.799111 #\n",
      "Epoch  33 => avg_loss: 0.022505\n",
      "# Validation loss => 0.048318 | f1-score: arg_iden = 0.889703 arg_class = 0.800977 #\n",
      "Epoch  34 => avg_loss: 0.022032\n",
      "# Validation loss => 0.051041 | f1-score: arg_iden = 0.888199 arg_class = 0.795916 #\n",
      "Epoch  35 => avg_loss: 0.021333\n",
      "# Validation loss => 0.050413 | f1-score: arg_iden = 0.889406 arg_class = 0.799960 #\n",
      "Epoch  36 => avg_loss: 0.020756\n",
      "# Validation loss => 0.050372 | f1-score: arg_iden = 0.890226 arg_class = 0.798797 #\n",
      "Epoch  37 => avg_loss: 0.020203\n",
      "# Validation loss => 0.051555 | f1-score: arg_iden = 0.888237 arg_class = 0.799231 #\n",
      "Epoch  38 => avg_loss: 0.019726\n",
      "# Validation loss => 0.050306 | f1-score: arg_iden = 0.885380 arg_class = 0.800697 #\n",
      "Epoch  39 => avg_loss: 0.019315\n",
      "# Validation loss => 0.051594 | f1-score: arg_iden = 0.889137 arg_class = 0.801624 #\n",
      "Epoch  40 => avg_loss: 0.018675\n",
      "# Validation loss => 0.052952 | f1-score: arg_iden = 0.888799 arg_class = 0.801665 #\n",
      "Epoch  41 => avg_loss: 0.018037\n",
      "# Validation loss => 0.053404 | f1-score: arg_iden = 0.887582 arg_class = 0.800000 #\n",
      "Epoch  42 => avg_loss: 0.017601\n",
      "# Validation loss => 0.053664 | f1-score: arg_iden = 0.887973 arg_class = 0.801165 #\n",
      "Epoch  43 => avg_loss: 0.017271\n",
      "# Validation loss => 0.052819 | f1-score: arg_iden = 0.887896 arg_class = 0.800162 #\n",
      "Epoch  44 => avg_loss: 0.016783\n",
      "# Validation loss => 0.053948 | f1-score: arg_iden = 0.888576 arg_class = 0.798673 #\n",
      "Epoch  45 => avg_loss: 0.016509\n",
      "# Validation loss => 0.055649 | f1-score: arg_iden = 0.884270 arg_class = 0.799516 #\n",
      "Epoch  46 => avg_loss: 0.016168\n",
      "# Validation loss => 0.054882 | f1-score: arg_iden = 0.886445 arg_class = 0.800693 #\n",
      "Epoch  47 => avg_loss: 0.015332\n",
      "# Validation loss => 0.056294 | f1-score: arg_iden = 0.888015 arg_class = 0.802137 #\n",
      "----- Best value obtained, saving model -----\n",
      "Epoch  48 => avg_loss: 0.014823\n",
      "# Validation loss => 0.056260 | f1-score: arg_iden = 0.887624 arg_class = 0.802886 #\n",
      "----- Best value obtained, saving model -----\n",
      "Epoch  49 => avg_loss: 0.014578\n",
      "# Validation loss => 0.056633 | f1-score: arg_iden = 0.888283 arg_class = 0.804848 #\n",
      "----- Best value obtained, saving model -----\n",
      "Epoch  50 => avg_loss: 0.014264\n",
      "# Validation loss => 0.057961 | f1-score: arg_iden = 0.889915 arg_class = 0.804014 #\n",
      "Epoch  51 => avg_loss: 0.014161\n",
      "# Validation loss => 0.055922 | f1-score: arg_iden = 0.888461 arg_class = 0.806403 #\n",
      "----- Best value obtained, saving model -----\n",
      "Epoch  52 => avg_loss: 0.013747\n",
      "# Validation loss => 0.058118 | f1-score: arg_iden = 0.887520 arg_class = 0.802504 #\n",
      "Epoch  53 => avg_loss: 0.012877\n",
      "# Validation loss => 0.059559 | f1-score: arg_iden = 0.885902 arg_class = 0.799798 #\n",
      "Epoch  54 => avg_loss: 0.013103\n",
      "# Validation loss => 0.059477 | f1-score: arg_iden = 0.890077 arg_class = 0.802340 #\n",
      "Epoch  55 => avg_loss: 0.012716\n",
      "# Validation loss => 0.059843 | f1-score: arg_iden = 0.888530 arg_class = 0.802302 #\n",
      "Epoch  56 => avg_loss: 0.012109\n",
      "# Validation loss => 0.059114 | f1-score: arg_iden = 0.885583 arg_class = 0.801223 #\n",
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/marco/miniconda3/envs/nlp2022-hw2/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3397, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_1445/806783136.py\", line 5, in <cell line: 5>\n",
      "    history = trainer.train(\n",
      "  File \"/mnt/c/Users/Marco/Desktop/Magistrale/NLP/projects/2022_hw2/nlp2022-hw2/hw2/stud/modelsTests/notebooks/../../../stud/modelsTests/utils/Trainer.py\", line 52, in train\n",
      "    dict_out = self.compute_forward(final_model.model, sample, device, optimizer = optimizer) # override\n",
      "  File \"/mnt/c/Users/Marco/Desktop/Magistrale/NLP/projects/2022_hw2/nlp2022-hw2/hw2/stud/modelsTests/notebooks/../../../stud/modelsTests/utils/Trainer_aic_transformer_embtest.py\", line 36, in compute_forward\n",
      "    predictions = model.forward(\n",
      "  File \"/mnt/c/Users/Marco/Desktop/Magistrale/NLP/projects/2022_hw2/nlp2022-hw2/hw2/stud/modelsTests/notebooks/../../../stud/modelsTests/model_arg_iden_class_part/Model_aic_transformer_embtest.py\", line 150, in forward\n",
      "    transformer_outs = self.transformer_model(**transformer_kwargs)\n",
      "  File \"/home/marco/miniconda3/envs/nlp2022-hw2/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1051, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/marco/miniconda3/envs/nlp2022-hw2/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py\", line 1017, in forward\n",
      "    encoder_outputs = self.encoder(\n",
      "  File \"/home/marco/miniconda3/envs/nlp2022-hw2/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1051, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/marco/miniconda3/envs/nlp2022-hw2/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py\", line 606, in forward\n",
      "    layer_outputs = layer_module(\n",
      "  File \"/home/marco/miniconda3/envs/nlp2022-hw2/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1051, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/marco/miniconda3/envs/nlp2022-hw2/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py\", line 534, in forward\n",
      "    layer_output = apply_chunking_to_forward(\n",
      "  File \"/home/marco/miniconda3/envs/nlp2022-hw2/lib/python3.9/site-packages/transformers/pytorch_utils.py\", line 241, in apply_chunking_to_forward\n",
      "    return forward_fn(*input_tensors)\n",
      "  File \"/home/marco/miniconda3/envs/nlp2022-hw2/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py\", line 546, in feed_forward_chunk\n",
      "    intermediate_output = self.intermediate(attention_output)\n",
      "  File \"/home/marco/miniconda3/envs/nlp2022-hw2/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1051, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/marco/miniconda3/envs/nlp2022-hw2/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py\", line 446, in forward\n",
      "    def forward(self, hidden_states: torch.Tensor) -> torch.Tensor:\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/marco/miniconda3/envs/nlp2022-hw2/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 1992, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/home/marco/miniconda3/envs/nlp2022-hw2/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1118, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/home/marco/miniconda3/envs/nlp2022-hw2/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1012, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/home/marco/miniconda3/envs/nlp2022-hw2/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 865, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/home/marco/miniconda3/envs/nlp2022-hw2/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 818, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(r))\n",
      "  File \"/home/marco/miniconda3/envs/nlp2022-hw2/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 736, in format_record\n",
      "    result += ''.join(_format_traceback_lines(frame_info.lines, Colors, self.has_colors, lvals))\n",
      "  File \"/home/marco/miniconda3/envs/nlp2022-hw2/lib/python3.9/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/marco/miniconda3/envs/nlp2022-hw2/lib/python3.9/site-packages/stack_data/core.py\", line 698, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"/home/marco/miniconda3/envs/nlp2022-hw2/lib/python3.9/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/marco/miniconda3/envs/nlp2022-hw2/lib/python3.9/site-packages/stack_data/core.py\", line 649, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"/home/marco/miniconda3/envs/nlp2022-hw2/lib/python3.9/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/marco/miniconda3/envs/nlp2022-hw2/lib/python3.9/site-packages/stack_data/core.py\", line 628, in executing_piece\n",
      "    return only(\n",
      "  File \"/home/marco/miniconda3/envs/nlp2022-hw2/lib/python3.9/site-packages/executing/executing.py\", line 164, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "from stud.modelsTests.utils.Trainer_aic_transformer_embtest import Trainer_aic_transformer_embtest\n",
    "\n",
    "trainer = Trainer_aic_transformer_embtest()\n",
    "\n",
    "history = trainer.train(\n",
    "    final_model, optimizer, dataloader_train_en, dataloader_dev_en,\n",
    "    epochs=60, device=device,\n",
    "    save_best=True, \n",
    "    min_score=0.8,\n",
    "    save_path_name=os.path.join(model_dir_path, 'arg_iden_class_net_weights.pth'),\n",
    "    saved_history=history\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLD TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_ex = torch.as_tensor([\n",
    "    [\n",
    "        [0,0,0,0,0,0,0,0,0,0, 0, 0], # for [CLS]\n",
    "        [0,1,0,0,0,0,0,0,0,0, 0, 0], # for This\n",
    "        [0,0,1,1,0,0,0,0,0,0, 0, 0], # for transform (+ ##er) (notice here!)\n",
    "        [0,0,0,0,0,0,0,0,0,0, 0, 0], # for ##er (notice here!, It's set to 0)\n",
    "        [0,0,0,0,1,0,0,0,0,0, 0, 0], # for is\n",
    "        [0,0,0,0,0,1,0,0,0,0, 0, 0], # for cool\n",
    "        [0,0,0,0,0,0,1,0,0,0, 0, 0], # for !\n",
    "        [0,0,0,0,0,0,0,0,0,0, 0, 0], # for [SEP]\n",
    "        [0,0,0,0,0,0,0,0,0,0, 0, 0], # for is (notice here!, It's set to 0)\n",
    "        [0,0,0,0,0,0,0,0,0,0, 0, 0], # for [SEP]\n",
    "        [0,0,0,0,0,0,0,0,0,0, 0, 0], # padding...\n",
    "        [0,0,0,0,0,0,0,0,0,0, 0, 0]  # ...padding\n",
    "    ],\n",
    "    [\n",
    "        [0,0,0,0,0,0,0,0,0,0, 0, 0], # for [CLS]\n",
    "        [0,1,0,0,0,0,0,0,0,0, 0, 0], # for This\n",
    "        [0,0,1,1,0,0,0,0,0,0, 0, 0], # for transform (+ ##er) (notice here!)\n",
    "        [0,0,0,0,0,0,0,0,0,0, 0, 0], # for ##er (notice here!, It's set to 0)\n",
    "        [0,0,0,0,1,0,0,0,0,0, 0, 0], # for is\n",
    "        [0,0,0,0,0,1,0,0,0,0, 0, 0], # for cool\n",
    "        [0,0,0,0,0,0,1,0,0,0, 0, 0], # for !\n",
    "        [0,0,0,0,0,0,0,0,0,0, 0, 0], # for [SEP]\n",
    "        [0,0,0,0,0,0,0,0,0,0, 0, 0], # for is (notice here!, It's set to 0)\n",
    "        [0,0,0,0,0,0,0,0,0,0, 0, 0], # for [SEP]\n",
    "        [0,0,0,0,0,0,0,0,0,0, 0, 0], # padding...\n",
    "        [0,0,0,0,0,0,0,0,0,0, 0, 0]  # ...padding\n",
    "    ],\n",
    "])\n",
    "\n",
    "out_model_ex = torch.as_tensor([\n",
    "    [ [-1,-1,-1], [1,1,1], [2,2,2], [2,2,0], [3,3,3], [4,4,4], [5,5,5], [-1,-1,-1], [3,3,3], [-1,-1,-1], [-1,-1,-1], [-1,-1,-1] ],\n",
    "    [ [-1,-1,-1], [1,1,1], [2,2,2], [2,2,0], [3,3,3], [4,4,4], [5,5,5], [-1,-1,-1], [3,3,3], [-1,-1,-1], [-1,-1,-1], [-1,-1,-1] ],\n",
    "])\n",
    "\n",
    "in_word_ids = torch.as_tensor([\n",
    "    [-1,0,1,1,2,3,4,-1,-1,-1,-1,-1],\n",
    "    [-1,0,1,1,2,3,4,-1,-1,-1,-1,-1],\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 12, 12]), torch.Size([2, 12, 3]))"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_ex.shape, out_model_ex.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0.],\n",
       "         [1., 1., 1.],\n",
       "         [2., 2., 1.],\n",
       "         [0., 0., 0.],\n",
       "         [3., 3., 3.],\n",
       "         [4., 4., 4.],\n",
       "         [5., 5., 5.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [1., 1., 1.],\n",
       "         [2., 2., 1.],\n",
       "         [0., 0., 0.],\n",
       "         [3., 3., 3.],\n",
       "         [4., 4., 4.],\n",
       "         [5., 5., 5.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]]])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_ex_reshaped = torch.swapaxes(matrix_ex,0,1)\n",
    "\n",
    "res_prod = (matrix_ex_reshaped[:,:,:,None] * out_model_ex[None,:,:,:])\n",
    "res_prod = torch.swapaxes(res_prod,0,1)\n",
    "\n",
    "matrix_ex_mask = matrix_ex.count_nonzero(-1)\n",
    "matrix_ex_mask = torch.where(matrix_ex_mask>0,matrix_ex_mask,1)\n",
    "\n",
    "matrix_computed = (res_prod.sum(dim=-2) / matrix_ex_mask[:,:,None])\n",
    "matrix_computed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 12, 3]), torch.Size([2, 12]))"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_computed.shape, in_word_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_computed_formatted = torch.zeros(matrix_computed.shape)\n",
    "for b, batch in enumerate(matrix_computed):\n",
    "    previous_id = None\n",
    "    for i, word_vector in enumerate(batch):\n",
    "        pos = in_word_ids[b][i]\n",
    "        if pos != -1 and pos != previous_id:\n",
    "            matrix_computed_formatted[b][pos] = matrix_computed[b][i]\n",
    "        previous_id = pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1.],\n",
       "         [2., 2., 1.],\n",
       "         [3., 3., 3.],\n",
       "         [4., 4., 4.],\n",
       "         [5., 5., 5.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [2., 2., 1.],\n",
       "         [3., 3., 3.],\n",
       "         [4., 4., 4.],\n",
       "         [5., 5., 5.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]]])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_computed_formatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "ee = nn.Embedding(3,10,0)\n",
    "lll = nn.Linear(3,10,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9684, -0.0348, -2.0594, -1.8089, -0.5899, -0.6094, -0.2437,  1.6009,\n",
       "         -1.1884,  1.4482],\n",
       "        [ 1.4010,  0.1630,  0.4457,  1.0707,  0.3655,  0.8652,  1.7827,  0.6841,\n",
       "          0.2043, -0.2954],\n",
       "        [ 1.4010,  0.1630,  0.4457,  1.0707,  0.3655,  0.8652,  1.7827,  0.6841,\n",
       "          0.2043, -0.2954]], grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ee( torch.as_tensor([1,2,2]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.7318,  0.1912, -0.2675, -0.0388, -0.2304, -0.1599, -0.2847,  0.4010,\n",
       "        -0.0373,  0.2144], grad_fn=<SqueezeBackward3>)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lll( torch.as_tensor([1.,1.,1.]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "176726de92aa5f7c7bad0ace42430d0e9e67427a9b4905ef1c48cfd9a71ff23e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('nlp2022-hw2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
