{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_input = {\n",
    "    \"dependency_heads\": [3,3,0,7,6,7,3,9,7,11,7,15,15,15,11,18,18,15,3],\n",
    "    \"dependency_relations\": [\"nsubj\",\"advmod\",\"root\",\"mark\",\"det\",\"nsubj\",\"ccomp\",\"amod\",\"obj\",\"mark\",\"advcl\",\"det\",\"amod\",\"amod\",\"obj\",\"case\",\"compound\",\"nmod\",\"punct\"],\n",
    "    \"lemmas\": [\"it\",\"also\",\"recommend\",\"that\",\"the\",\"authority\",\"take\",\"appropriate\",\"measure\",\"to\",\"meet\",\"the\",\"specific\",\"educational\",\"need\",\"of\",\"Roma\",\"child\",\".\"],\n",
    "    \"pos_tags\": [\"PRON\",\"ADV\",\"VERB\",\"SCONJ\",\"DET\",\"NOUN\",\"VERB\",\"ADJ\",\"NOUN\",\"PART\",\"VERB\",\"DET\",\"ADJ\",\"ADJ\",\"NOUN\",\"ADP\",\"PROPN\",\"NOUN\",\"PUNCT\"],\n",
    "    \"predicates\": [\"_\",\"_\",\"PROPOSE\",\"_\",\"_\",\"_\",\"CARRY-OUT-ACTION\",\"_\",\"_\",\"_\",\"SATISFY_FULFILL\",\"_\",\"_\",\"_\",\"_\",\"_\",\"_\",\"_\",\"_\"], \n",
    "    \"words\": [\n",
    "        \"It\",\"also\",\"recommends\",\"that\",\"the\",\"authorities\",\"take\",\"appropriate\",\"measures\",\"to\",\n",
    "        \"meet\",\"the\",\"specific\",\"educational\",\"needs\",\"of\",\"Roma\",\"children\",\".\"],\n",
    "    \"roles\": {\n",
    "        \"2\": [\"_\",\"agent\",\"_\",\"topic\",\"_\",\"_\",\"_\",\"_\",\"_\",\"_\",\"_\",\"_\",\"_\",\"_\",\"_\",\"_\",\"_\",\"_\",\"_\"],\n",
    "        \"6\": [\"_\",\"_\",\"_\",\"_\",\"_\",\"agent\",\"_\",\"_\",\"patient\",\"goal\",\"_\",\"_\",\"_\",\"_\",\"_\",\"_\",\"_\",\"_\",\"_\"],\n",
    "        \"10\": [\"_\",\"_\",\"_\",\"_\",\"_\",\"_\",\"_\",\"_\",\"_\",\"_\",\"_\",\"_\",\"_\",\"_\",\"theme\",\"_\",\"_\",\"_\",\"_\"]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'It also recommends that the authorities take appropriate measures to meet the specific educational needs of Roma children .'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_text = ' '.join(example_input['words'])\n",
    "sample_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "http_url = 'https://verbatlas.org/api/model'\n",
    "http_input = [{'text':sample_text, 'lang':'EN'}]\n",
    "x = requests.post(http_url, json = http_input)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'tokens': [{'index': 0, 'rawText': 'It'},\n",
       "   {'index': 1, 'rawText': 'also'},\n",
       "   {'index': 2, 'rawText': 'recommends'},\n",
       "   {'index': 3, 'rawText': 'that'},\n",
       "   {'index': 4, 'rawText': 'the'},\n",
       "   {'index': 5, 'rawText': 'authorities'},\n",
       "   {'index': 6, 'rawText': 'take'},\n",
       "   {'index': 7, 'rawText': 'appropriate'},\n",
       "   {'index': 8, 'rawText': 'measures'},\n",
       "   {'index': 9, 'rawText': 'to'},\n",
       "   {'index': 10, 'rawText': 'meet'},\n",
       "   {'index': 11, 'rawText': 'the'},\n",
       "   {'index': 12, 'rawText': 'specific'},\n",
       "   {'index': 13, 'rawText': 'educational'},\n",
       "   {'index': 14, 'rawText': 'needs'},\n",
       "   {'index': 15, 'rawText': 'of'},\n",
       "   {'index': 16, 'rawText': 'Roma'},\n",
       "   {'index': 17, 'rawText': 'children'},\n",
       "   {'index': 18, 'rawText': '.'}],\n",
       "  'annotations': [{'tokenIndex': 2,\n",
       "    'verbatlas': {'frameName': 'PROPOSE',\n",
       "     'roles': [{'role': 'Agent', 'score': 1.0, 'span': [0, 1]},\n",
       "      {'role': 'Topic', 'score': 1.0, 'span': [3, 18]}]},\n",
       "    'englishPropbank': {'frameName': 'recommend.01',\n",
       "     'roles': [{'role': 'ARG0', 'score': 1.0, 'span': [0, 1]},\n",
       "      {'role': 'ARGM-DIS', 'score': 1.0, 'span': [1, 2]},\n",
       "      {'role': 'ARG1', 'score': 1.0, 'span': [3, 18]}]},\n",
       "    'chinesePropbank': {'frameName': '建议.01',\n",
       "     'roles': [{'role': 'A0', 'score': 1.0, 'span': [0, 1]},\n",
       "      {'role': 'DIS', 'score': 1.0, 'span': [1, 2]},\n",
       "      {'role': 'A1', 'score': 1.0, 'span': [3, 18]}]},\n",
       "    'germanPropbank': {'frameName': 'empfehlen.1',\n",
       "     'roles': [{'role': 'A0', 'score': 1.0, 'span': [0, 1]},\n",
       "      {'role': 'A1', 'score': 1.0, 'span': [3, 4]},\n",
       "      {'role': 'A1', 'score': 1.0, 'span': [4, 18]}]},\n",
       "    'pdtVallex': {'frameName': 'v-w672f1', 'roles': []},\n",
       "    'spanishAncora': {'frameName': 'recomendar.a32',\n",
       "     'roles': [{'role': 'arg0-agt', 'score': 1.0, 'span': [0, 1]},\n",
       "      {'role': 'arg1-pat', 'score': 1.0, 'span': [3, 18]}]},\n",
       "    'catalanAncora': {'frameName': 'recomanar.a32',\n",
       "     'roles': [{'role': 'arg0-agt', 'score': 1.0, 'span': [0, 1]},\n",
       "      {'role': 'arg1-pat', 'score': 1.0, 'span': [3, 18]}]}},\n",
       "   {'tokenIndex': 6,\n",
       "    'verbatlas': {'frameName': 'TAKE',\n",
       "     'roles': [{'role': 'Agent', 'score': 1.0, 'span': [4, 6]},\n",
       "      {'role': 'Theme', 'score': 1.0, 'span': [7, 18]}]},\n",
       "    'englishPropbank': {'frameName': 'take.01',\n",
       "     'roles': [{'role': 'ARG0', 'score': 1.0, 'span': [4, 6]},\n",
       "      {'role': 'ARG1', 'score': 1.0, 'span': [7, 18]}]},\n",
       "    'chinesePropbank': {'frameName': '采取.01',\n",
       "     'roles': [{'role': 'A0', 'score': 1.0, 'span': [4, 6]},\n",
       "      {'role': 'A1', 'score': 1.0, 'span': [7, 9]},\n",
       "      {'role': 'PRP', 'score': 1.0, 'span': [9, 18]}]},\n",
       "    'germanPropbank': {'frameName': 'nehmen.15',\n",
       "     'roles': [{'role': 'A0', 'score': 1.0, 'span': [4, 6]},\n",
       "      {'role': 'A1', 'score': 1.0, 'span': [7, 18]}]},\n",
       "    'pdtVallex': {'frameName': 'v-w5161f4',\n",
       "     'roles': [{'role': 'ACT', 'score': 1.0, 'span': [0, 1]},\n",
       "      {'role': 'EFF', 'score': 1.0, 'span': [4, 18]}]},\n",
       "    'spanishAncora': {'frameName': 'tomar.a2',\n",
       "     'roles': [{'role': 'arg0-agt', 'score': 1.0, 'span': [4, 6]},\n",
       "      {'role': 'arg1-pat', 'score': 1.0, 'span': [7, 9]},\n",
       "      {'role': 'argM-fin', 'score': 1.0, 'span': [9, 18]}]},\n",
       "    'catalanAncora': {'frameName': 'prendre.a2',\n",
       "     'roles': [{'role': 'arg0-agt', 'score': 1.0, 'span': [4, 6]},\n",
       "      {'role': 'arg1-pat', 'score': 1.0, 'span': [7, 9]},\n",
       "      {'role': 'argM-fin', 'score': 1.0, 'span': [9, 18]}]}},\n",
       "   {'tokenIndex': 8,\n",
       "    'verbatlas': {'frameName': '_', 'roles': []},\n",
       "    'englishPropbank': {'frameName': '_', 'roles': []},\n",
       "    'chinesePropbank': {'frameName': '_', 'roles': []},\n",
       "    'germanPropbank': {'frameName': '_', 'roles': []},\n",
       "    'pdtVallex': {'frameName': 'v-w3111f1', 'roles': []},\n",
       "    'spanishAncora': {'frameName': '_', 'roles': []},\n",
       "    'catalanAncora': {'frameName': '_', 'roles': []}},\n",
       "   {'tokenIndex': 10,\n",
       "    'verbatlas': {'frameName': 'SATISFY_FULFILL',\n",
       "     'roles': [{'role': 'Agent', 'score': 1.0, 'span': [4, 6]},\n",
       "      {'role': 'Agent', 'score': 1.0, 'span': [7, 9]},\n",
       "      {'role': 'Theme', 'score': 1.0, 'span': [11, 18]}]},\n",
       "    'englishPropbank': {'frameName': 'meet.01',\n",
       "     'roles': [{'role': 'ARG0', 'score': 1.0, 'span': [4, 6]},\n",
       "      {'role': 'ARG0', 'score': 1.0, 'span': [7, 9]},\n",
       "      {'role': 'ARG1', 'score': 1.0, 'span': [11, 18]}]},\n",
       "    'chinesePropbank': {'frameName': '尽.01',\n",
       "     'roles': [{'role': 'MNR', 'score': 1.0, 'span': [7, 8]},\n",
       "      {'role': 'A1', 'score': 1.0, 'span': [11, 18]}]},\n",
       "    'germanPropbank': {'frameName': 'bezahlen.2',\n",
       "     'roles': [{'role': 'A0', 'score': 1.0, 'span': [4, 6]},\n",
       "      {'role': 'A0', 'score': 1.0, 'span': [7, 9]},\n",
       "      {'role': 'A1', 'score': 1.0, 'span': [11, 18]}]},\n",
       "    'pdtVallex': {'frameName': 'v-w6347f1', 'roles': []},\n",
       "    'spanishAncora': {'frameName': 'cumplir.a2',\n",
       "     'roles': [{'role': 'arg0-agt', 'score': 1.0, 'span': [4, 6]},\n",
       "      {'role': 'arg0-agt', 'score': 1.0, 'span': [7, 9]},\n",
       "      {'role': 'arg1-pat', 'score': 1.0, 'span': [11, 18]}]},\n",
       "    'catalanAncora': {'frameName': 'complir.a2',\n",
       "     'roles': [{'role': 'arg0-agt', 'score': 1.0, 'span': [7, 9]},\n",
       "      {'role': 'arg1-pat', 'score': 1.0, 'span': [11, 18]}]}},\n",
       "   {'tokenIndex': 14,\n",
       "    'verbatlas': {'frameName': '_', 'roles': []},\n",
       "    'englishPropbank': {'frameName': 'need.01',\n",
       "     'roles': [{'role': 'ARGM-ADJ', 'score': 1.0, 'span': [12, 13]},\n",
       "      {'role': 'ARG1', 'score': 1.0, 'span': [13, 14]},\n",
       "      {'role': 'ARG0', 'score': 1.0, 'span': [15, 18]}]},\n",
       "    'chinesePropbank': {'frameName': '_', 'roles': []},\n",
       "    'germanPropbank': {'frameName': '_', 'roles': []},\n",
       "    'pdtVallex': {'frameName': '_', 'roles': []},\n",
       "    'spanishAncora': {'frameName': '_', 'roles': []},\n",
       "    'catalanAncora': {'frameName': '_', 'roles': []}}]}]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "x_json = json.loads(x.text)\n",
    "x_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dependency_heads': [3, 3, 0, 7, 6, 7, 3, 9, 7, 11, 7, 15, 15, 15, 11, 18, 18, 15, 3], 'dependency_relations': ['nsubj', 'advmod', 'root', 'mark', 'det', 'nsubj', 'ccomp', 'amod', 'obj', 'mark', 'advcl', 'det', 'amod', 'amod', 'obj', 'case', 'compound', 'nmod', 'punct'], 'lemmas': ['it', 'also', 'recommend', 'that', 'the', 'authority', 'take', 'appropriate', 'measure', 'to', 'meet', 'the', 'specific', 'educational', 'need', 'of', 'Roma', 'child', '.'], 'pos_tags': ['PRON', 'ADV', 'VERB', 'SCONJ', 'DET', 'NOUN', 'VERB', 'ADJ', 'NOUN', 'PART', 'VERB', 'DET', 'ADJ', 'ADJ', 'NOUN', 'ADP', 'PROPN', 'NOUN', 'PUNCT'], 'predicates': ['_', '_', 'PROPOSE', '_', '_', '_', 'CARRY-OUT-ACTION', '_', '_', '_', 'SATISFY_FULFILL', '_', '_', '_', '_', '_', '_', '_', '_'], 'words': ['It', 'also', 'recommends', 'that', 'the', 'authorities', 'take', 'appropriate', 'measures', 'to', 'meet', 'the', 'specific', 'educational', 'needs', 'of', 'Roma', 'children', '.'], 'roles': {'2': ['_', 'agent', '_', 'topic', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], '6': ['_', '_', '_', '_', '_', 'agent', '_', '_', 'patient', 'goal', '_', '_', '_', '_', '_', '_', '_', '_', '_'], '10': ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', 'theme', '_', '_', '_', '_']}}\n",
      "\n",
      "\n",
      "[{'roles': {2: ['_', 'agent', '_', 'topic', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], 6: ['_', '_', '_', '_', '_', '_', 'agent', 'theme', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_'], 10: ['_', '_', '_', '_', '_', '_', 'agent', 'agent', '_', '_', '_', 'theme', '_', '_', '_', '_', '_', '_', '_']}, 'words': ['It', 'also', 'recommends', 'that', 'the', 'authorities', 'take', 'appropriate', 'measures', 'to', 'meet', 'the', 'specific', 'educational', 'needs', 'of', 'Roma', 'children', '.'], 'predicates': ['_', '_', 'PROPOSE', '_', '_', '_', 'TAKE', '_', '_', '_', 'SATISFY_FULFILL', '_', '_', '_', '_', '_', '_', '_', '_']}]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "def format_response(response_text):\n",
    "    null_tag = '_'\n",
    "    phrases_formatted = []\n",
    "    x_json = json.loads(response_text) if type(response_text) is str else response_text # response.text\n",
    "    \n",
    "    for phrase in x_json:\n",
    "        x_formatted = {'roles':{}}\n",
    "        # words\n",
    "        x_formatted['words'] = [e['rawText'] for e in phrase['tokens']]\n",
    "        # predicates + roles\n",
    "        x_formatted['predicates'] = [null_tag]*len(phrase['tokens'])\n",
    "        for annotation in phrase['annotations']:\n",
    "            i = annotation['tokenIndex']\n",
    "            if annotation['verbatlas']['frameName'] != null_tag: #TODO: roles!\n",
    "                x_formatted['predicates'][i] = annotation['verbatlas']['frameName']\n",
    "\n",
    "                x_formatted['roles'][i] = [null_tag]*len(phrase['tokens'])\n",
    "\n",
    "                for j, role_for_i in enumerate(annotation['verbatlas']['roles']):\n",
    "                    span_pos = role_for_i['span'][1 if j==0 else 0]\n",
    "                    x_formatted['roles'][i][span_pos] = role_for_i['role'].lower()\n",
    "\n",
    "        # in the end, append!\n",
    "        phrases_formatted.append(x_formatted)\n",
    "\n",
    "    return phrases_formatted\n",
    "\n",
    "print(example_input)\n",
    "print('\\n')\n",
    "print( format_response(x.text) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type([1,2,3]) == list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OTHER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "from copy import deepcopy\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "def load_data(lang_data_path):\n",
    "    f = open(lang_data_path)\n",
    "    res = json.load( f )\n",
    "    f.close()\n",
    "    return res\n",
    "\n",
    "def list_to_phrase(l_w):\n",
    "    phrase = ' '.join(l_w) if type(l_w) == list else l_w\n",
    "    phrase = re.sub(r'( \\')','\\'',phrase)\n",
    "    phrase = re.sub(r'( ’)','’',phrase)\n",
    "    phrase = re.sub(r'(\\b\\. )|(\\b\\.$)',' . ',phrase)\n",
    "    return phrase\n",
    "\n",
    "def reconstruct_subwords(text_str_input, verbatlas_out, amuse_out):\n",
    "    va_l = [ e['rawText'] for e in verbatlas_out['tokens'] ]\n",
    "    am_l = [ e['text'] for e in amuse_out['tokens'] ]\n",
    "\n",
    "    for i in range(len(verbatlas_out['annotations'])):\n",
    "        l_k = list(verbatlas_out['annotations'][i].keys())\n",
    "        for k in l_k:\n",
    "            if k != 'tokenIndex' and k != 'verbatlas':\n",
    "                verbatlas_out['annotations'][i].pop(k,None)\n",
    "\n",
    "    if len(va_l) == len(am_l):\n",
    "        return text_str_input, verbatlas_out, amuse_out\n",
    "    \n",
    "    text_l = text_str_input.split(' ')\n",
    "    r_v_i = deepcopy(verbatlas_out)\n",
    "    r_a_i = deepcopy(amuse_out)\n",
    "\n",
    "    # verbatlas\n",
    "    text_i = 0; json_i = 0\n",
    "    while json_i < len(r_v_i['tokens']):\n",
    "\n",
    "        edit_v = r_v_i['tokens'][json_i]['rawText'].lower() != text_l[text_i].lower()\n",
    "\n",
    "        if not edit_v:\n",
    "            text_i += 1; json_i += 1\n",
    "            continue\n",
    "\n",
    "        # for the predicates and roles\n",
    "\n",
    "        for ii in range(len(r_v_i['annotations'])):\n",
    "            r_v_i['annotations'][ii]['tokenIndex'] = r_v_i['annotations'][ii]['tokenIndex'] - 1 \\\n",
    "            if r_v_i['annotations'][ii]['tokenIndex'] > json_i else r_v_i['annotations'][ii]['tokenIndex']\n",
    "            for iii in range(len(r_v_i['annotations'][ii]['verbatlas']['roles'])):\n",
    "                for iiii in [0,1]:\n",
    "                    r_v_i['annotations'][ii]['verbatlas']['roles'][iii]['span'][iiii] = \\\n",
    "                    r_v_i['annotations'][ii]['verbatlas']['roles'][iii]['span'][iiii] -1 \\\n",
    "                    if r_v_i['annotations'][ii]['verbatlas']['roles'][iii]['span'][iiii] > json_i \\\n",
    "                    else r_v_i['annotations'][ii]['verbatlas']['roles'][iii]['span'][iiii]\n",
    "\n",
    "        r_v_i['tokens'][json_i]['rawText'] += r_v_i['tokens'][json_i+1]['rawText']\n",
    "\n",
    "        for ii in range( json_i+2 , len(r_v_i['tokens']) ):\n",
    "            r_v_i['tokens'][ii]['index'] -= 1\n",
    "\n",
    "        del r_v_i['tokens'][json_i+1]\n",
    "\n",
    "    # amuse\n",
    "    text_i = 0; json_i = 0\n",
    "    while json_i < len(r_a_i['tokens']):\n",
    "\n",
    "        edit_a = r_a_i['tokens'][json_i]['text'].lower() != text_l[text_i].lower()\n",
    "\n",
    "        if not edit_a:\n",
    "            text_i += 1; json_i += 1\n",
    "            continue\n",
    "\n",
    "        r_a_i['tokens'][json_i]['text'] += r_a_i['tokens'][json_i+1]['text']\n",
    "\n",
    "        for ii in range( json_i+2 , len(r_a_i['tokens']) ):\n",
    "            r_a_i['tokens'][ii]['index'] -= 1\n",
    "\n",
    "        del r_a_i['tokens'][json_i+1]\n",
    "            \n",
    "                        \n",
    "    return text_str_input, r_v_i, r_a_i\n",
    "    \n",
    "\n",
    "def retrieve_data(data, verbatlas_link, amuse_link, lang=\"EN\", chunk_dim=1):\n",
    "    null_tag = '_'\n",
    "    roles_precedence = [\n",
    "        'NOUN','PROPN','ADP','PART','SCONJ','PRON','VERB','NUM',\n",
    "        'ADJ','ADV','DET','PUNCT','SYM','AUX','X','CCONJ',\n",
    "        'SPACE','INTJ', # added\n",
    "    ]\n",
    "    result = {}\n",
    "\n",
    "    sentences_skipped = 0\n",
    "    to_send = []\n",
    "\n",
    "    pbar = tqdm(enumerate(data.items()))\n",
    "\n",
    "    for data_i, (data_sample_key,data_sample_value) in pbar:\n",
    "\n",
    "        text_sampled = list_to_phrase(data_sample_value['words'])\n",
    "\n",
    "        to_send.append({ 'text': text_sampled, 'lang':lang, 'key_id':data_sample_key })\n",
    "        if len(to_send)%chunk_dim != 0:\n",
    "            continue\n",
    "        \n",
    "        pbar.set_description(f'percentage: {((data_i+1)/len(data)):.4f} (index={data_i})')\n",
    "\n",
    "        res_v = requests.post(verbatlas_link, json = to_send)\n",
    "        res_a = requests.post(amuse_link, json = to_send)\n",
    "        status_code_good = res_v.status_code == 200 and res_a.status_code == 200\n",
    "\n",
    "        if not status_code_good:\n",
    "            print(f'verbatlas={res_v.status_code} | amuse={res_a.status_code} | skipping chunk!')\n",
    "            sentences_skipped += len(to_send)\n",
    "            to_send = []\n",
    "\n",
    "        res_v = json.loads(res_v.text)\n",
    "        res_a = json.loads(res_a.text)\n",
    "        for t_i, r_v_i, r_a_i in zip(to_send, res_v, res_a):\n",
    "            \n",
    "            ti_text, r_v_i, r_a_i = reconstruct_subwords(t_i['text'], r_v_i, r_a_i)\n",
    "            t_i['text'] = ti_text\n",
    "\n",
    "            k_id = t_i['key_id']\n",
    "\n",
    "            result[k_id] = {'roles':{}}\n",
    "            # pos_tags\n",
    "            result[k_id]['pos_tags'] = [ e['pos'] for e in r_a_i['tokens'] ]\n",
    "            # lemmas\n",
    "            result[k_id]['lemmas'] = [ e['lemma'] for e in r_a_i['tokens'] ]\n",
    "            # words\n",
    "            result[k_id]['words'] = [ e['rawText'] for e in r_v_i['tokens'] ]\n",
    "\n",
    "            try:\n",
    "                assert len(result[k_id]['lemmas']) == len(result[k_id]['words'])\n",
    "            except:\n",
    "                print(t_i['text'])\n",
    "                print([ e['text'] for e in r_a_i['tokens'] ])\n",
    "                print(result[k_id]['words'])\n",
    "                raise Exception('error.')\n",
    "\n",
    "            # predicates + roles\n",
    "            result[k_id]['predicates'] = [null_tag]*len(r_v_i['tokens'])\n",
    "            for annotation in r_v_i['annotations']:\n",
    "                tokenIndex = annotation['tokenIndex']\n",
    "                if annotation['verbatlas']['frameName'] != null_tag: # TODO: roles!\n",
    "                    result[k_id]['predicates'][tokenIndex] = annotation['verbatlas']['frameName']\n",
    "\n",
    "                    result[k_id]['roles'][str(tokenIndex)] = [null_tag]*len(r_v_i['tokens'])\n",
    "\n",
    "                    for _, role_for_i in enumerate(annotation['verbatlas']['roles']):\n",
    "                        span_pos = role_for_i['span']\n",
    "                        \n",
    "                        # TODO: use span!\n",
    "                        pos_best_value = 999 # the less the better\n",
    "                        best_index = span_pos[0]\n",
    "                        for span_pos_i in range(span_pos[0],span_pos[1]+1):\n",
    "                            try:\n",
    "                                r_a_i['tokens'][span_pos_i]['pos']\n",
    "                            except:\n",
    "                                continue\n",
    "                            if r_a_i['tokens'][span_pos_i]['pos'] in roles_precedence:\n",
    "                                pos_value = roles_precedence.index( r_a_i['tokens'][span_pos_i]['pos'] )\n",
    "                            else:\n",
    "                                print('Warn: pos value not present:',r_a_i['tokens'][span_pos_i]['pos'])\n",
    "                                pos_value = 999\n",
    "                            if pos_value < pos_best_value:\n",
    "                                pos_best_value = pos_value\n",
    "                                best_index = span_pos_i\n",
    "                                \n",
    "                        result[k_id]['roles'][str(tokenIndex)][best_index] = role_for_i['role'].lower()\n",
    "                \n",
    "        to_send = []\n",
    "    \n",
    "    print(f'skipped {sentences_skipped} sentences out of {len(data.values())}')\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbatlas_url = 'http://127.0.0.1:3001/api/model'\n",
    "amuse_url = 'http://127.0.0.1:3002/api/model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We urge the parties to refrain from the use of force and provocative acts , which only serve to undermine the peace process , and we appeal to them to take immediate steps to create the necessary environment for a restoration of peace , stability and the continuation of talks leading to a comprehensive , just and lasting peace based on Security Council resolutions 242 ( 1967 ) and 338 ( 1973 ) .\n"
     ]
    }
   ],
   "source": [
    "test_str = \"We urge the parties to refrain from the use of force and provocative acts , which only serve to undermine the peace process , and we appeal to them to take immediate steps to create the necessary environment for a restoration of peace , stability and the continuation of talks leading to a comprehensive , just and lasting peace based on Security Council resolutions 242 ( 1967 ) and 338 ( 1973 ) .\"\n",
    "test_str = list_to_phrase(test_str)\n",
    "print(test_str)\n",
    "\n",
    "ee = json.loads(requests.post(amuse_url, json = [{'text':test_str,'lang':'EN'}]).text)[0]\n",
    "aa = json.loads(requests.post(verbatlas_url, json = [{'text':test_str,'lang':'EN'}]).text)[0]\n",
    "\n",
    "rt, rv, ra = reconstruct_subwords(test_str, aa, ee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "errorrr = 'Mr . Lozinsky ( Russian Federation ) said that his delegation had taken note of the positive evaluation by the International Civil Service Commission ( ICSC ) of the activities of the Working Group on the Framework for Human Resources Management .'\n",
    "\n",
    "vvvvv = json.loads(requests.post(verbatlas_url, json = [{'text':errorrr,'lang':'EN'}]).text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_data = load_data('../../../../data/EN/train.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "percentage: 0.0434 (index=238): : 238it [01:11,  3.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "verbatlas=500 | amuse=200 | skipping chunk!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "percentage: 0.2312 (index=1271): : 1271it [06:00,  2.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "verbatlas=500 | amuse=200 | skipping chunk!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "percentage: 0.2516 (index=1383): : 1382it [06:31,  5.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "verbatlas=500 | amuse=200 | skipping chunk!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "percentage: 0.2723 (index=1497): : 1497it [07:01,  2.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "verbatlas=500 | amuse=200 | skipping chunk!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "percentage: 0.5734 (index=3153): : 3152it [14:54,  3.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "verbatlas=500 | amuse=200 | skipping chunk!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "percentage: 0.8040 (index=4422): : 4422it [21:18,  5.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "verbatlas=500 | amuse=200 | skipping chunk!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "percentage: 0.8088 (index=4448): : 4447it [21:24,  4.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "verbatlas=500 | amuse=200 | skipping chunk!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "percentage: 0.8746 (index=4810): : 4810it [23:07,  5.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "verbatlas=500 | amuse=200 | skipping chunk!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "percentage: 0.8889 (index=4889): : 4888it [23:29,  3.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "verbatlas=500 | amuse=200 | skipping chunk!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "percentage: 0.9455 (index=5200): : 5200it [25:03,  3.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "verbatlas=500 | amuse=200 | skipping chunk!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "percentage: 0.9502 (index=5226): : 5225it [25:10,  3.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "verbatlas=500 | amuse=200 | skipping chunk!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "percentage: 1.0000 (index=5500): : 5501it [26:42,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipped 11 sentences out of 5501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "en_to_send = retrieve_data(en_data, verbatlas_url, amuse_url, lang=\"EN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('../../../../data/EN/train_autogenerated.json', 'w') as outfile:\n",
    "    json.dump(en_to_send, outfile, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dependency_heads': [3, 3, 0, 8, 7, 7, 8, 3, 10, 8, 13, 13, 10, 3],\n",
       " 'dependency_relations': ['nsubj',\n",
       "  'advmod',\n",
       "  'root',\n",
       "  'mark',\n",
       "  'det',\n",
       "  'amod',\n",
       "  'nsubj',\n",
       "  'ccomp',\n",
       "  'amod',\n",
       "  'obj',\n",
       "  'case',\n",
       "  'amod',\n",
       "  'nmod',\n",
       "  'punct'],\n",
       " 'lemmas': ['member',\n",
       "  'also',\n",
       "  'ask',\n",
       "  'whether',\n",
       "  'all',\n",
       "  'social',\n",
       "  'group',\n",
       "  'enjoy',\n",
       "  'equal',\n",
       "  'access',\n",
       "  'to',\n",
       "  'higher',\n",
       "  'education',\n",
       "  '.'],\n",
       " 'pos_tags': ['NOUN',\n",
       "  'ADV',\n",
       "  'VERB',\n",
       "  'SCONJ',\n",
       "  'DET',\n",
       "  'ADJ',\n",
       "  'NOUN',\n",
       "  'VERB',\n",
       "  'ADJ',\n",
       "  'NOUN',\n",
       "  'ADP',\n",
       "  'ADJ',\n",
       "  'NOUN',\n",
       "  'PUNCT'],\n",
       " 'predicates': ['_',\n",
       "  '_',\n",
       "  'ASK_REQUEST',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  'BENEFIT_EXPLOIT',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_'],\n",
       " 'roles': {'2': ['agent',\n",
       "   '_',\n",
       "   '_',\n",
       "   'theme',\n",
       "   '_',\n",
       "   '_',\n",
       "   '_',\n",
       "   '_',\n",
       "   '_',\n",
       "   '_',\n",
       "   '_',\n",
       "   '_',\n",
       "   '_',\n",
       "   '_'],\n",
       "  '7': ['_',\n",
       "   '_',\n",
       "   '_',\n",
       "   '_',\n",
       "   '_',\n",
       "   '_',\n",
       "   'beneficiary',\n",
       "   '_',\n",
       "   '_',\n",
       "   'theme',\n",
       "   '_',\n",
       "   '_',\n",
       "   '_',\n",
       "   '_']},\n",
       " 'words': ['Members',\n",
       "  'also',\n",
       "  'asked',\n",
       "  'whether',\n",
       "  'all',\n",
       "  'social',\n",
       "  'groups',\n",
       "  'enjoyed',\n",
       "  'equal',\n",
       "  'access',\n",
       "  'to',\n",
       "  'higher',\n",
       "  'education',\n",
       "  '.']}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(en_data.values())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'roles': {2: ['agent',\n",
       "   '_',\n",
       "   '_',\n",
       "   '_',\n",
       "   '_',\n",
       "   '_',\n",
       "   'theme',\n",
       "   '_',\n",
       "   '_',\n",
       "   '_',\n",
       "   '_',\n",
       "   '_',\n",
       "   '_',\n",
       "   '_'],\n",
       "  7: ['_',\n",
       "   '_',\n",
       "   '_',\n",
       "   '_',\n",
       "   '_',\n",
       "   '_',\n",
       "   'experiencer',\n",
       "   '_',\n",
       "   '_',\n",
       "   'stimulus',\n",
       "   '_',\n",
       "   '_',\n",
       "   '_',\n",
       "   '_']},\n",
       " 'words': ['Members',\n",
       "  'also',\n",
       "  'asked',\n",
       "  'whether',\n",
       "  'all',\n",
       "  'social',\n",
       "  'groups',\n",
       "  'enjoyed',\n",
       "  'equal',\n",
       "  'access',\n",
       "  'to',\n",
       "  'higher',\n",
       "  'education',\n",
       "  '.'],\n",
       " 'predicates': ['_',\n",
       "  '_',\n",
       "  'ASK_REQUEST',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  'ENJOY',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_']}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(en_to_send.values())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_data_sample = list(en_data.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "pos_counter = Counter()\n",
    "\n",
    "for e in en_data_sample:\n",
    "    if 'roles' in e:\n",
    "        # print(e['words'])\n",
    "        for i, r in e['roles'].items():\n",
    "            idx = int(i)\n",
    "            # print(f\"predicate = {e['predicates'][idx]}\")\n",
    "            for r_i, r_v in enumerate(r):\n",
    "                if r_v != '_':\n",
    "                    pos_tag = e['pos_tags'][r_i]\n",
    "                    # print(f\"role_word = {e['words'][r_i]} | role = {r_v} | pos = {pos_tag}\")\n",
    "                    pos_counter[pos_tag] += 1\n",
    "    # print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_verbatlas = requests.post(verbatlas_url, json = en_to_send)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_amuse = requests.post(amuse_url, json = en_to_send)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "176726de92aa5f7c7bad0ace42430d0e9e67427a9b4905ef1c48cfd9a71ff23e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('nlp2022-hw2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
